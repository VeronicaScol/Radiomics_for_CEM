{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cf9e2e-cb49-46f9-b7a9-1522682b4562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_path = r\"\"\n",
    "\n",
    "# ============================================================\n",
    "# One-stop pipeline:\n",
    "# - loads train/test/external LE + RE CSVs\n",
    "# - standardizes mask id column -> \"mask_name\"\n",
    "# - checks LE vs RE outcomes (per split) and reports mismatches\n",
    "# - merges LE+RE features on mask_name\n",
    "# - returns finished dataframes with [\"mask_name\", \"outcome\", ...]\n",
    "# - saves merged CSVs (optional)\n",
    "# ============================================================\n",
    "\n",
    "def _standardize_mask_id(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Make sure the mask/path identifier column is named 'mask_name' and drop junk index columns.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # common case: double-saved index column + actual mask column\n",
    "    if \"Unnamed: 0.1\" in df.columns and \"Unnamed: 0\" in df.columns:\n",
    "        df = df.drop(columns=[\"Unnamed: 0.1\"], errors=\"ignore\")\n",
    "        df = df.rename(columns={\"Unnamed: 0\": \"mask_name\"})\n",
    "    elif \"Unnamed: 0\" in df.columns:\n",
    "        df = df.rename(columns={\"Unnamed: 0\": \"mask_name\"})\n",
    "\n",
    "    if \"mask_name\" not in df.columns:\n",
    "        raise ValueError(\"Could not find mask identifier column. Expected 'Unnamed: 0' or 'mask_name'.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _load_features_csv(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Read CSV robustly and standardize id column.\"\"\"\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    df = _standardize_mask_id(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _dedup_on_mask(df: pd.DataFrame, file_label: str) -> pd.DataFrame:\n",
    "    \"\"\"Drop duplicate mask_name rows (keep first) and warn.\"\"\"\n",
    "    df = df.copy()\n",
    "    dups = df[\"mask_name\"].duplicated().sum()\n",
    "    if dups:\n",
    "        print(f\"WARNING [{file_label}]: {dups} duplicate mask_name rows found; keeping first occurrence.\")\n",
    "        df = df.drop_duplicates(subset=[\"mask_name\"], keep=\"first\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def _merge_split(le_df: pd.DataFrame, re_df: pd.DataFrame, split_name: str,\n",
    "                 prefix_le=\"LE__\", prefix_re=\"RE__\",\n",
    "                 prefer=\"LE\", show_mismatches=10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge LE + RE on mask_name, keeping one outcome column.\n",
    "    - Checks outcome consistency (where both present).\n",
    "    - Outcome resolution: prefer LE else RE (or vice versa).\n",
    "    \"\"\"\n",
    "    le_df = _dedup_on_mask(le_df, f\"{split_name}/LE\")\n",
    "    re_df = _dedup_on_mask(re_df, f\"{split_name}/RE\")\n",
    "\n",
    "    # Ensure outcome exists\n",
    "    if \"outcome\" not in le_df.columns or \"outcome\" not in re_df.columns:\n",
    "        raise ValueError(f\"[{split_name}] Both LE and RE must contain an 'outcome' column.\")\n",
    "\n",
    "    # Coerce outcome to numeric (handles strings like \"3\")\n",
    "    le_df = le_df.copy()\n",
    "    re_df = re_df.copy()\n",
    "    le_df[\"outcome\"] = pd.to_numeric(le_df[\"outcome\"], errors=\"coerce\")\n",
    "    re_df[\"outcome\"] = pd.to_numeric(re_df[\"outcome\"], errors=\"coerce\")\n",
    "\n",
    "    # Align outcomes on mask_name and check conflicts\n",
    "    meta = pd.merge(\n",
    "        le_df[[\"mask_name\", \"outcome\"]],\n",
    "        re_df[[\"mask_name\", \"outcome\"]],\n",
    "        on=\"mask_name\",\n",
    "        how=\"inner\",\n",
    "        suffixes=(\"_le\", \"_re\"),\n",
    "    )\n",
    "\n",
    "    both_present = meta[\"outcome_le\"].notna() & meta[\"outcome_re\"].notna()\n",
    "    conflict = both_present & (meta[\"outcome_le\"] != meta[\"outcome_re\"])\n",
    "\n",
    "    print(f\"\\n[{split_name}] rows LE={len(le_df)} | RE={len(re_df)} | matched={len(meta)}\")\n",
    "    print(f\"[{split_name}] outcomes both present={both_present.sum()} | conflicts={conflict.sum()}\")\n",
    "\n",
    "    if conflict.any():\n",
    "        print(f\"[{split_name}] Example outcome conflicts (showing up to {show_mismatches}):\")\n",
    "        print(meta.loc[conflict, [\"mask_name\", \"outcome_le\", \"outcome_re\"]].head(show_mismatches))\n",
    "\n",
    "    # Resolve to single outcome\n",
    "    if prefer.upper() == \"LE\":\n",
    "        meta[\"outcome\"] = meta[\"outcome_le\"].combine_first(meta[\"outcome_re\"])\n",
    "    else:\n",
    "        meta[\"outcome\"] = meta[\"outcome_re\"].combine_first(meta[\"outcome_le\"])\n",
    "    meta = meta[[\"mask_name\", \"outcome\"]]\n",
    "\n",
    "    # Prefix features (exclude mask_name/outcome)\n",
    "    le_feat = le_df.drop(columns=[\"mask_name\", \"outcome\"], errors=\"ignore\").add_prefix(prefix_le)\n",
    "    re_feat = re_df.drop(columns=[\"mask_name\", \"outcome\"], errors=\"ignore\").add_prefix(prefix_re)\n",
    "\n",
    "    le_pref = pd.concat([le_df[[\"mask_name\"]], le_feat], axis=1)\n",
    "    re_pref = pd.concat([re_df[[\"mask_name\"]], re_feat], axis=1)\n",
    "\n",
    "    # Merge meta + features\n",
    "    merged = (\n",
    "        meta.merge(le_pref, on=\"mask_name\", how=\"inner\")\n",
    "            .merge(re_pref, on=\"mask_name\", how=\"inner\")\n",
    "    )\n",
    "\n",
    "    # Ensure first two columns are mask_name, outcome\n",
    "    cols = [\"mask_name\", \"outcome\"] + [c for c in merged.columns if c not in [\"mask_name\", \"outcome\"]]\n",
    "    merged = merged[cols]\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "def build_all_splits(\n",
    "    base_dir: str,\n",
    "    *,\n",
    "    train_re=\"train_features_true_mask.csv\",\n",
    "    train_le=\"train_features_true_mask_low_energy.csv\",\n",
    "    test_re=\"test_features_true_mask.csv\",\n",
    "    test_le=\"test_features_true_mask_low_energy.csv\",\n",
    "    external_re=\"external_features_true_mask.csv\",\n",
    "    external_le=\"external_features_true_mask_low_energy_v2.csv\",  # set to v2 by default\n",
    "    prefix_le=\"LE__\",\n",
    "    prefix_re=\"RE__\",\n",
    "    prefer_outcome=\"LE\",\n",
    "    save_merged=True,\n",
    "    out_suffix=\"_merged_LE_RE.csv\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns: (train_df, test_df, external_df) with mask_name + outcome first.\n",
    "    Also saves to CSV if save_merged=True.\n",
    "    \"\"\"\n",
    "    def p(name): return os.path.join(base_dir, name)\n",
    "\n",
    "    # Load\n",
    "    train_le_df = _load_features_csv(p(train_le))\n",
    "    train_re_df = _load_features_csv(p(train_re))\n",
    "    test_le_df  = _load_features_csv(p(test_le))\n",
    "    test_re_df  = _load_features_csv(p(test_re))\n",
    "    ext_le_df   = _load_features_csv(p(external_le))\n",
    "    ext_re_df   = _load_features_csv(p(external_re))\n",
    "\n",
    "    # Merge each split\n",
    "    train_df = _merge_split(train_le_df, train_re_df, \"TRAIN\",\n",
    "                            prefix_le=prefix_le, prefix_re=prefix_re, prefer=prefer_outcome)\n",
    "    test_df  = _merge_split(test_le_df,  test_re_df,  \"TEST\",\n",
    "                            prefix_le=prefix_le, prefix_re=prefix_re, prefer=prefer_outcome)\n",
    "    ext_df   = _merge_split(ext_le_df,   ext_re_df,   \"EXTERNAL\",\n",
    "                            prefix_le=prefix_le, prefix_re=prefix_re, prefer=prefer_outcome)\n",
    "\n",
    "    # Save outputs\n",
    "    if save_merged:\n",
    "        train_out = p(\"train\" + out_suffix)\n",
    "        test_out  = p(\"test\" + out_suffix)\n",
    "        ext_out   = p(\"external\" + out_suffix)\n",
    "\n",
    "        train_df.to_csv(train_out, index=False)\n",
    "        test_df.to_csv(test_out, index=False)\n",
    "        ext_df.to_csv(ext_out, index=False)\n",
    "\n",
    "        print(\"\\nSaved merged files:\")\n",
    "        print(\" -\", train_out)\n",
    "        print(\" -\", test_out)\n",
    "        print(\" -\", ext_out)\n",
    "\n",
    "    return train_df, test_df, ext_df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# USAGE (run this)\n",
    "# =========================\n",
    "# base_dir should be your folder that contains the 6 CSVs (and v2 LE external if present)\n",
    "# You already have data_path set earlier; use it here:\n",
    "train_df, test_df, external_df = build_all_splits(\n",
    "    base_dir=data_path,\n",
    "    external_le=\"external_features_true_mask_low_energy_v2.csv\",  # change if your v2 file name differs\n",
    "    save_merged=True\n",
    ")\n",
    "\n",
    "# Now you have finished dataframes in memory:\n",
    "# train_df, test_df, external_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db05437-37b1-4c0d-af34-5fb5873279c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_df[\"LE__original_shape2D_MajorAxisLength\"]\n",
    " == train_df[\"RE__original_shape2D_MajorAxisLength\"]).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415e69e-8d2b-43a1-ac16-1d9795dcae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = train_df[\"LE__original_shape2D_MajorAxisLength\"] - train_df[\"RE__original_shape2D_MajorAxisLength\"]\n",
    "diff.abs().max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b86bd-9942-4f38-ab3c-29fc56f0efe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "le_cols = [c for c in train_df.columns if c.startswith(\"LE__\")]\n",
    "re_cols = [c for c in train_df.columns if c.startswith(\"RE__\")]\n",
    "\n",
    "le_map = {c.replace(\"LE__\", \"\"): c for c in le_cols}\n",
    "re_map = {c.replace(\"RE__\", \"\"): c for c in re_cols}\n",
    "\n",
    "common = sorted(set(le_map) & set(re_map))\n",
    "\n",
    "identical = []\n",
    "different = []\n",
    "\n",
    "for feat in common:\n",
    "    a = train_df[le_map[feat]]\n",
    "    b = train_df[re_map[feat]]\n",
    "\n",
    "    if np.allclose(a, b, rtol=1e-6, atol=1e-8, equal_nan=True):\n",
    "        identical.append(feat)\n",
    "    else:\n",
    "        different.append(feat)\n",
    "\n",
    "print(f\"Identical features: {len(identical)}\")\n",
    "print(f\"Different features: {len(different)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b368c3-5e04-40a4-87bb-4d698bef919b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
