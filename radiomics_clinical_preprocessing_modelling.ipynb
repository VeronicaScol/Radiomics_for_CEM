{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce52ea82-9e2f-4b01-b86c-cadb5538ff03",
   "metadata": {},
   "source": [
    "# PIPELINE DATA LOADING AND PREPROCESSING\n",
    "This notebook documents the data loading, preprocessing of radiomics features, and feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32766547-ad4a-4037-bbf9-1d57fa51fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import ntpath\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Import from radiomics_pipeline\n",
    "from radiomics_pipeline.utils import preprocessing_train, preprocessing_test, get_results, get_ci, get_stats_with_ci, get_ci_for_auc, get_optimal_threshold\n",
    "from modeling_pipeline_utils import get_optimal_classweight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fa9e6-1b3c-48ef-9d86-53a03d0381a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### STEP 1: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30995f3-5ec9-4b30-b31a-77ac9345628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select your mode. option: test or external\n",
    "mode = 'external'\n",
    "\n",
    "#path to your folder where the following files are present: train_merged_LE_RE.csv, test_merged_LE_RE.csv, external_test.csv, \n",
    "#combined_clinical_features_train_processed.csv, combined_clinical_features_test_processed.csv, combined_clinical_features_external_processed.csv\n",
    "path = \"\"\n",
    "\n",
    "# training data\n",
    "df_features_train = pd.read_csv(os.path.join(path, \"train_merged_LE_RE.csv\"))\n",
    "\n",
    "outcome_train = df_features_train[\"outcome\"].tolist()\n",
    "df_features_train.drop([\"mask_name\", \"outcome\"], axis=1, inplace=True)\n",
    "\n",
    "if mode == \"test\":\n",
    "    df_features_test = pd.read_csv(os.path.join(path, \"test_merged_LE_RE.csv\"))\n",
    "\n",
    "    outcome_test = df_features_test[\"outcome\"].tolist()\n",
    "    df_features_test.drop([\"mask_name\", \"outcome\"], axis=1, inplace=True)\n",
    "\n",
    "elif mode == \"external\":\n",
    "    df_features_external = pd.read_csv(os.path.join(path, \"external_test.csv\"))\n",
    "\n",
    "    outcome_external = df_features_external[\"outcome\"].tolist()\n",
    "    df_features_external.drop([\"mask_name\", \"outcome\"], axis=1, inplace=True)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"mode must be 'test' or 'external'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32f667-9037-46cc-9447-f997ba7ad59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_radiomics_train = pd.read_csv(os.path.join(path, \"train_merged_LE_RE.csv\"))\n",
    "clinical_train = pd.read_csv(os.path.join(path, \"combined_clinical_features_train_processed.csv\"))\n",
    "\n",
    "\n",
    "if mode == \"test\":\n",
    "    # Load radiomics\n",
    "    df_radiomics_test = pd.read_csv(os.path.join(path, \"test_merged_LE_RE.csv\"))\n",
    "\n",
    "    # Load clinical\n",
    "    clinical_test = pd.read_csv(os.path.join(path, \"combined_clinical_features_test_processed.csv\"))\n",
    "\n",
    "elif mode == \"external\":\n",
    "    # Load radiomics\n",
    "    df_radiomics_external = pd.read_csv(os.path.join(path, \"external_test.csv\"))\n",
    "\n",
    "    # Load clinical\n",
    "    clinical_external = pd.read_csv(os.path.join(path, \"combined_clinical_features_external_processed.csv\"))\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"mode must be 'test' or 'external'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d65eaa-08af-4f20-94f4-1d601c1cb9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean strings\n",
    "df_radiomics_train[\"mask_name\"] = df_radiomics_train[\"mask_name\"].astype(str).str.strip()\n",
    "clinical_train[\"UM_ID\"] = clinical_train[\"UM_ID\"].astype(str).str.strip()\n",
    "\n",
    "# Extract patient ID\n",
    "df_radiomics_train[\"patient_id\"] = df_radiomics_train[\"mask_name\"].str.extract(r'(MUMC_\\d+)')[0]\n",
    "\n",
    "# Rename clinical column\n",
    "clinical_train = clinical_train.rename(columns={\"UM_ID\": \"patient_id\"})\n",
    "\n",
    "# Drop outcome columns\n",
    "outcome_cols = [col for col in clinical_train.columns if col.startswith(\"Final diagnosis_\")]\n",
    "clinical_train = clinical_train.drop(columns=outcome_cols, errors=\"ignore\")\n",
    "\n",
    "\n",
    "if mode == \"test\":\n",
    "    # Clean strings\n",
    "    df_radiomics_test[\"mask_name\"] = df_radiomics_test[\"mask_name\"].astype(str).str.strip()\n",
    "    clinical_test[\"UM_ID\"] = clinical_test[\"UM_ID\"].astype(str).str.strip()\n",
    "\n",
    "    # Extract patient ID\n",
    "    df_radiomics_test[\"patient_id\"] = df_radiomics_test[\"mask_name\"].str.extract(r'(MUMC_\\d+)')[0]\n",
    "\n",
    "    # Rename clinical column\n",
    "    clinical_test = clinical_test.rename(columns={\"UM_ID\": \"patient_id\"})\n",
    "\n",
    "    # Drop outcome columns\n",
    "    clinical_test = clinical_test.drop(columns=outcome_cols, errors=\"ignore\")\n",
    "\n",
    "elif mode == \"external\":\n",
    "    # Clean strings\n",
    "    df_radiomics_external[\"mask_name\"] = df_radiomics_external[\"mask_name\"].astype(str).str.strip()\n",
    "    clinical_external[\"Patient Number \"] = clinical_external[\"Patient Number \"].astype(str).str.strip()\n",
    "\n",
    "    # Extract patient ID\n",
    "    df_radiomics_external[\"patient_id\"] = df_radiomics_external[\"mask_name\"].str.extract(r'(Patient\\d{3})')[0]\n",
    "\n",
    "    # Rename clinical column\n",
    "    clinical_external = clinical_external.rename(columns={\"Patient Number \": \"patient_id\"})\n",
    "\n",
    "    # Drop outcome columns\n",
    "    outcome_cols = [col for col in clinical_external.columns if col.startswith(\"Final diagnosis_\")]\n",
    "    clinical_external = clinical_external.drop(columns=outcome_cols, errors=\"ignore\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"mode must be 'test' or 'external'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b5006-3930-487b-ba42-4bbbb5b1256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on the extracted patient_id (left join = keep all lesions)\n",
    "df_combined_train = pd.merge(\n",
    "    df_radiomics_train,\n",
    "    clinical_train,\n",
    "    on=\"patient_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_clinical\")\n",
    ")\n",
    "\n",
    "# Extract outcomes from radiomics\n",
    "outcome_train = df_combined_train[\"outcome\"].tolist()\n",
    "\n",
    "# Drop identifier columns (only keep pure features)\n",
    "drop_cols = [\"mask_name\", \"outcome\", \"patient_id\"]\n",
    "df_features_train = df_combined_train.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "# Quick success check (train)\n",
    "print(\"Combined train shape:\", df_features_train.shape)  # Should be ~ (1811, ~1334+clinical_cols)\n",
    "print(\"Any missing patient_id after extraction?\", df_radiomics_train[\"patient_id\"].isnull().sum())\n",
    "print(\"Example patient_ids from radiomics:\", df_radiomics_train[\"patient_id\"].head(5).tolist())\n",
    "\n",
    "if mode == \"test\":\n",
    "    df_combined_test = pd.merge(\n",
    "        df_radiomics_test,\n",
    "        clinical_test,\n",
    "        on=\"patient_id\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_clinical\")\n",
    "    )\n",
    "\n",
    "    outcome_test = df_combined_test[\"outcome\"].tolist()\n",
    "\n",
    "    drop_cols = [\"mask_name\", \"outcome\", \"patient_id\"]\n",
    "    df_features_test = df_combined_test.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "    # Quick success check (test)\n",
    "    print(\"Combined test shape:\", df_features_test.shape)\n",
    "    print(\"Any missing patient_id after extraction?\", df_radiomics_test[\"patient_id\"].isnull().sum())\n",
    "    print(\"Example patient_ids from radiomics:\", df_radiomics_test[\"patient_id\"].head(5).tolist())\n",
    "\n",
    "elif mode == \"external\":\n",
    "    df_combined_external = pd.merge(\n",
    "        df_radiomics_external,\n",
    "        clinical_external,\n",
    "        on=\"patient_id\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_clinical\")\n",
    "    )\n",
    "\n",
    "    outcome_external = df_combined_external[\"outcome\"].tolist()\n",
    "\n",
    "    drop_cols = [\"mask_name\", \"outcome\", \"patient_id\"]\n",
    "    df_features_external = df_combined_external.drop(columns=drop_cols, errors=\"ignore\")\n",
    "\n",
    "    # Quick success check (external)\n",
    "    print(\"Combined external shape:\", df_features_external.shape)\n",
    "    print(\"Any missing patient_id after extraction?\", df_radiomics_external[\"patient_id\"].isnull().sum())\n",
    "    print(\"Example patient_ids from radiomics:\", df_radiomics_external[\"patient_id\"].head(5).tolist())\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"mode must be 'test' or 'external'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e6bccf-0afb-4d15-81c5-b188c390a4ce",
   "metadata": {},
   "source": [
    "### STEP 2: Preprocessing features\n",
    "The preprocessing of the features is present in radiomics_pipeline.utils.\n",
    "\n",
    "It includes:\n",
    "- Normalization\n",
    "- Low variance feature removal (variance below 0.01)\n",
    "- Highly correlated feature removal (Spearman correlation matrix, correlation > 0.85, dropping one feature based on heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27713778-e73f-4608-ae3d-0fbc1ccd9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std, selector, to_drop, decor_dataset_train = preprocessing_train(df_features_train)\n",
    "\n",
    "if mode == \"test\":\n",
    "    decor_dataset_test = preprocessing_test(\n",
    "        df_features_test, mean_std, selector, to_drop\n",
    "    )\n",
    "\n",
    "elif mode == \"external\":\n",
    "    decor_dataset_external = preprocessing_test(\n",
    "        df_features_external, mean_std, selector, to_drop\n",
    "    )\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"mode must be 'test' or 'external'\")\n",
    "\n",
    "print(\"features processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c55dc7-e97b-42b9-9cab-0786f85a747c",
   "metadata": {},
   "source": [
    "### STEP 3: Select optimal features \n",
    "#### WRAPPER FEATURE SELECTION: Recursive Feature Elimination with cross-validation\n",
    "The model currently used is XGBClassifier, it is possible to change it to compare different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5603e0-7b37-4e6f-a529-b163d711866f",
   "metadata": {},
   "source": [
    "#### RECURSIVE FEATURE ELIMINATION (NO CROSS VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929804cf-0531-4bd3-9b87-ff96e3db2a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model: XGBoost Classifier\n",
    "import xgboost as xgb\n",
    "optimal_classweight = get_optimal_classweight(outcome_train)\n",
    "model = xgb.XGBClassifier(\n",
    "    gamma=0.5,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=3,\n",
    "    min_child_weight=5,\n",
    "    n_estimators=890,\n",
    "    use_label_encoder=False,\n",
    "    colsample_bytree=1,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    nthread=4,\n",
    "    scale_pos_weight= optimal_classweight,\n",
    "    random_state=27\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09a397-e8aa-4b29-8496-70d2e7a505dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfe = RFE(estimator=model, n_features_to_select=11, step=1)\n",
    "rfe.fit(decor_dataset_train, outcome_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f843bd-fc21-4867-9bc3-d9dd16532715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: Extract selected features immediately after fit\n",
    "support = rfe.support_\n",
    "selected_features = decor_dataset_train.columns[support].tolist()\n",
    "\n",
    "print(f\"Selected exactly {len(selected_features)} features (as requested):\")\n",
    "print(selected_features)\n",
    "\n",
    "reduced_features_train = decor_dataset_train[selected_features].copy()\n",
    "\n",
    "print(\"\\nReduced train shape:\", reduced_features_train.shape)   # Should be (1811, 11)\n",
    "\n",
    "if mode == \"test\":\n",
    "    reduced_features_test = decor_dataset_test[selected_features].copy()\n",
    "\n",
    "    print(\"Reduced test shape: \", reduced_features_test.shape)     \n",
    "\n",
    "elif mode == \"external\":\n",
    "    reduced_features_external = decor_dataset_external[selected_features].copy()\n",
    "\n",
    "    print(\"Reduced external shape: \", reduced_features_external.shape)  \n",
    "\n",
    "else:\n",
    "    raise ValueError(\"mode must be 'test' or 'external'\")\n",
    "\n",
    "print(\"Model expects:\", rfe.estimator_.n_features_in_, \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d810f8-84a9-4ebe-becd-56eec4194141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ── Define output directory once ──\n",
    "save_dir = os.path.expanduser(\"~/Documents/Features\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(f\"Results will be saved to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a17995-6baa-4e43-97be-380a30687bc2",
   "metadata": {},
   "source": [
    "#### MODEL TRAINING : XGBOOST + EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d10fb-d978-4347-972a-951d9ba7f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the selected features only\n",
    "filtered_col = np.extract(support, np.array(decor_dataset_train.columns))\n",
    "reduced_features_train = decor_dataset_train[filtered_col]\n",
    "\n",
    "if mode == \"test\":\n",
    "    filtered_col = np.extract(support, np.array(decor_dataset_test.columns))\n",
    "    reduced_features_test = decor_dataset_test[filtered_col]\n",
    "\n",
    "elif mode == \"external\":\n",
    "    filtered_col = np.extract(support, np.array(decor_dataset_external.columns))\n",
    "    reduced_features_external = decor_dataset_external[filtered_col]\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"mode must be 'test' or 'external'\")\n",
    "\n",
    "print(\"features processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c5a85-f9df-44cf-b060-8d57df31a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"test\":\n",
    "    path_images_test = list(df_features_test.index)\n",
    "\n",
    "    # predict case by case for test\n",
    "    all_predictions = []\n",
    "    for i, index in enumerate(path_images_test):\n",
    "        temp_proba = rfe.estimator_.predict_proba(\n",
    "            reduced_features_test.iloc[i].values.reshape(1, -1)\n",
    "        )\n",
    "        all_predictions.append(temp_proba)\n",
    "\n",
    "    all_predictions_test = np.array([prediction[0][1] for prediction in all_predictions])\n",
    "\n",
    "    file = open(\n",
    "        os.path.expanduser(\"~/Documents/Features\") + \"/\"\n",
    "        + ntpath.basename(\"/probabilities_test\").split(\".\")[0] + \".pkl\",\n",
    "        \"wb\"\n",
    "    )\n",
    "    pickle.dump(all_predictions_test, file)\n",
    "    file.close()\n",
    "\n",
    "elif mode == \"external\":\n",
    "    path_images_external = list(df_features_external.index)\n",
    "\n",
    "    # predict case by case for external\n",
    "    all_predictions = []\n",
    "    for i, index in enumerate(path_images_external):\n",
    "        temp_proba = rfe.estimator_.predict_proba(\n",
    "            reduced_features_external.iloc[i].values.reshape(1, -1)\n",
    "        )\n",
    "        all_predictions.append(temp_proba)\n",
    "\n",
    "    all_predictions_external = np.array(\n",
    "        [prediction[0][1] for prediction in all_predictions]\n",
    "    )\n",
    "\n",
    "    file = open(\n",
    "        os.path.expanduser(\"~/Documents/Features\") + \"/\"\n",
    "        + ntpath.basename(\"/probabilities_external\").split(\".\")[0] + \".pkl\",\n",
    "        \"wb\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efc490-7287-4808-bc17-e14605825a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DETERMINING THE OPTIMAL THRESHHOLD FOR CLASSIFICATION BOUNDARY\n",
    "## This is not for evaluation since it is on the training dataset.\n",
    "\n",
    "path_images_train = list(df_features_train.index)\n",
    "\n",
    "#predict case by case for train to obtain optimal threshhold\n",
    "\n",
    "all_predictions = []\n",
    "for i,index in enumerate(path_images_train):\n",
    "        temp_proba = rfe.estimator_.predict_proba(reduced_features_train.iloc[i].values.reshape(1, -1)) #look into what estimator_ does\n",
    "        all_predictions.append(temp_proba)\n",
    "\n",
    "all_predictions_train = np.array([prediction[0][1] for prediction in all_predictions])\n",
    "\n",
    "file = open(os.path.expanduser(\"~/Documents/Features\") + \"/\" + ntpath.basename(\"/probabilities_train\").split(\".\")[0]+\".pkl\", \"wb\")\n",
    "pickle.dump(all_predictions_train, file)\n",
    "file.close()\n",
    "\n",
    "#Determine optimal threshhold\n",
    "\n",
    "optimal_threshold = get_optimal_threshold(outcome_train, all_predictions_train) # (true_outcome, predictions): to obtain a good threshold based on the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf5f56-76b1-490c-959e-979f46b6d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94f233-9258-4d5f-ad2d-45025cd6c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"test\":\n",
    "    outcome_test_array = np.array(outcome_test)\n",
    "    df_distributions, df_results = get_stats_with_ci(\n",
    "        outcome_test_array,\n",
    "        all_predictions_test,\n",
    "        \"test_set_results\",\n",
    "        optimal_threshold\n",
    "    )\n",
    "\n",
    "elif mode == \"external\":\n",
    "    outcome_external_array = np.array(outcome_external)\n",
    "\n",
    "    df_distributions, df_results = get_stats_with_ci(\n",
    "        outcome_external_array,\n",
    "        all_predictions_external,\n",
    "        \"external_set_results\",\n",
    "        optimal_threshold\n",
    "    )\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"mode must be 'test' or 'external'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bdb333-b8f8-4a9b-88a0-b78403f1b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb884e47-6363-4a78-a80d-501d8d094506",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"test\":\n",
    "    predictions_test_binary = (np.array(all_predictions_test) > optimal_threshold).astype(int)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(\n",
    "        y_true=outcome_test_array,\n",
    "        y_pred=predictions_test_binary,\n",
    "        normalize=\"true\"\n",
    "    )\n",
    "    disp = sklearn.metrics.ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm,\n",
    "        display_labels=rfe.classes_\n",
    "    )\n",
    "    disp.plot()\n",
    "\n",
    "elif mode == \"external\":\n",
    "    predictions_external_binary = (\n",
    "        np.array(all_predictions_external) > optimal_threshold\n",
    "    ).astype(int)\n",
    "\n",
    "    cm = sklearn.metrics.confusion_matrix(\n",
    "        y_true=outcome_external_array,\n",
    "        y_pred=predictions_external_binary,\n",
    "        normalize=\"true\"\n",
    "    )\n",
    "    disp = sklearn.metrics.ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm,\n",
    "        display_labels=rfe.classes_\n",
    "    )\n",
    "    disp.plot()\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"mode must be 'test' or 'external'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb317f-3397-4a0d-8696-ecd0a6997e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_name = \"RFE Classifier\"\n",
    "\n",
    "if mode == \"test\":\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(\n",
    "        outcome_test,\n",
    "        all_predictions_test\n",
    "    )\n",
    "    roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax.plot(\n",
    "        fpr, tpr, lw=2,\n",
    "        label=f'{model_name} (AUC = {roc_auc:.3f})',\n",
    "        color='purple'\n",
    "    )\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier (AUC = 0.500)')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "    ax.set_title('ROC Curve', fontsize=14)\n",
    "    ax.legend(loc=\"lower right\", fontsize=15)\n",
    "    ax.grid(alpha=1)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "elif mode == \"external\":\n",
    "    fpr, tpr, thresholds = sklearn.metrics.roc_curve(\n",
    "        outcome_external,\n",
    "        all_predictions_external\n",
    "    )\n",
    "    roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "    ax.plot(\n",
    "        fpr, tpr, lw=2,\n",
    "        label=f'{model_name} (AUC = {roc_auc:.3f})',\n",
    "        color='purple'\n",
    "    )\n",
    "    ax.plot(\n",
    "        [0, 1], [0, 1],\n",
    "        'k--', lw=2,\n",
    "        label='Random Classifier (AUC = 0.500)'\n",
    "    )\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "    ax.set_title('ROC Curve', fontsize=14)\n",
    "    ax.legend(loc=\"lower right\", fontsize=15)\n",
    "    ax.grid(alpha=1)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"mode must be 'test' or 'external'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc7e4f0-383b-474a-a705-0de5a6490210",
   "metadata": {},
   "source": [
    "## SHAP VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d2d85a-d13e-4412-8b46-865417f0d9bd",
   "metadata": {},
   "source": [
    "##### XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f059d-4bd9-44f1-a929-447ea958e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "X100 = shap.utils.sample(reduced_features_train, 100) # I am not yet sure what the optimal number for distribution is. Standard (explained in documentation is 100.\n",
    "explainer_xgb = shap.Explainer(rfe.estimator_, X100) #This utilises the rfe xgboost with 10 features\n",
    "shap_values_xgb = explainer_xgb(reduced_features_train) #based on training dataset of model, since that is what controls final model architecture\n",
    "shap.plots.beeswarm(shap_values_xgb, max_display = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbf32b-afe4-41d4-bd04-c00ddf24f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_case = random.randint(0, len(reduced_features_train + 1))\n",
    "print(\"case index: \" + str(random_case))\n",
    "\n",
    "shap.plots.waterfall(shap_values_xgb[random_case], max_display = 11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
