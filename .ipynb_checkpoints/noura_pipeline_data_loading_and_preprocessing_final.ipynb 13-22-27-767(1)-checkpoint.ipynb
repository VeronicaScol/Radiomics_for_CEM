{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce52ea82-9e2f-4b01-b86c-cadb5538ff03",
   "metadata": {},
   "source": [
    "# PIPELINE DATA LOADING AND PREPROCESSING\n",
    "This notebook documents the data loading, preprocessing of radiomics features, and feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32766547-ad4a-4037-bbf9-1d57fa51fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap\n",
    "!pip install xgboost\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import ntpath\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Import from radiomics_pipeline\n",
    "from radiomics_pipeline.utils import preprocessing_train, preprocessing_test, get_results, get_ci, get_stats_with_ci, get_ci_for_auc, get_optimal_threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fa9e6-1b3c-48ef-9d86-53a03d0381a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### STEP 1: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30995f3-5ec9-4b30-b31a-77ac9345628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load features\n",
    "df_features_train = pd.read_csv(\"\")\n",
    "outcome_train = list(df_features_train[\"outcome\"])\n",
    "df_features_train.drop([\"mask_name\",\"outcome\"], inplace=True, axis=1)\n",
    "df_features_test = pd.read_csv(\"\")\n",
    "outcome_test = list(df_features_test[\"outcome\"])\n",
    "df_features_test.drop([\"mask_name\",\"outcome\"], inplace=True, axis=1)\n",
    "\n",
    "#The below gives the error 'Outcome' (not a column in df features test), this has to be fixed in the merge file itself.\n",
    "\n",
    "#df_features_external = pd.read_csv(\"~/Documents/Features/external_merged_LE_RE.csv\")\n",
    "#outcome_external = list(df_features_test[\"outcome\"])\n",
    "#df_features_external.drop([\"mask_name\",\"outcome\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32f667-9037-46cc-9447-f997ba7ad59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load radiomics (same as above)\n",
    "df_radiomics_train = pd.read_csv(\"\")\n",
    "df_radiomics_test  = pd.read_csv(\"\")\n",
    "\n",
    "# Load clinical\n",
    "clinical_train = pd.read_csv(\"\")\n",
    "clinical_test  = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b5006-3930-487b-ba42-4bbbb5b1256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean strings (good practice)\n",
    "df_radiomics_train[\"mask_name\"] = df_radiomics_train[\"mask_name\"].astype(str).str.strip()\n",
    "df_radiomics_test[\"mask_name\"]  = df_radiomics_test[\"mask_name\"].astype(str).str.strip()\n",
    "\n",
    "clinical_train[\"UM_ID\"] = clinical_train[\"UM_ID\"].astype(str).str.strip()\n",
    "clinical_test[\"UM_ID\"]  = clinical_test[\"UM_ID\"].astype(str).str.strip()\n",
    "\n",
    "# Extract MUMC_XXXX from the full path ──\n",
    "df_radiomics_train[\"patient_id\"] = df_radiomics_train[\"mask_name\"].str.extract(r'(MUMC_\\d+)')[0]\n",
    "df_radiomics_test[\"patient_id\"]  = df_radiomics_test[\"mask_name\"].str.extract(r'(MUMC_\\d+)')[0]\n",
    "\n",
    "# Rename clinical column to match\n",
    "clinical_train = clinical_train.rename(columns={\"UM_ID\": \"patient_id\"})\n",
    "clinical_test  = clinical_test.rename(columns={\"UM_ID\": \"patient_id\"})\n",
    "\n",
    "# Drop any clinical outcome columns (to avoid leakage)\n",
    "outcome_cols = [col for col in clinical_train.columns if col.startswith(\"Final diagnosis_\")]\n",
    "clinical_train = clinical_train.drop(columns=outcome_cols, errors='ignore')\n",
    "clinical_test  = clinical_test.drop(columns=outcome_cols, errors='ignore')\n",
    "\n",
    "# Merge on the extracted patient_id (left join = keep all lesions)\n",
    "df_combined_train = pd.merge(\n",
    "    df_radiomics_train,\n",
    "    clinical_train,\n",
    "    on=\"patient_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_clinical\")\n",
    ")\n",
    "\n",
    "df_combined_test = pd.merge(\n",
    "    df_radiomics_test,\n",
    "    clinical_test,\n",
    "    on=\"patient_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_clinical\")\n",
    ")\n",
    "\n",
    "# Extract outcomes from radiomics\n",
    "outcome_train = df_combined_train[\"outcome\"].tolist()\n",
    "outcome_test  = df_combined_test[\"outcome\"].tolist()\n",
    "\n",
    "# Drop identifier columns (only keep pure features)\n",
    "drop_cols = [\"mask_name\", \"outcome\", \"patient_id\"]\n",
    "df_features_train = df_combined_train.drop(columns=drop_cols, errors='ignore')\n",
    "df_features_test  = df_combined_test.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "# Quick success check\n",
    "print(\"Combined train shape:\", df_features_train.shape)  # Should be ~ (1811, ~1334+clinical_cols)\n",
    "print(\"Any missing patient_id after extraction?\", df_radiomics_train[\"patient_id\"].isnull().sum())\n",
    "print(\"Example patient_ids from radiomics:\", df_radiomics_train[\"patient_id\"].head(5).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e6bccf-0afb-4d15-81c5-b188c390a4ce",
   "metadata": {},
   "source": [
    "### STEP 2: Preprocessing features\n",
    "The preprocessing of the features is present in radiomics_pipeline.utils.\n",
    "\n",
    "It includes:\n",
    "- Normalization\n",
    "- Low variance feature removal (variance below 0.01)\n",
    "- Highly correlated feature removal (Spearman correlation matrix, correlation > 0.85, dropping one feature based on heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27713778-e73f-4608-ae3d-0fbc1ccd9945",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std, selector, to_drop, decor_dataset_train = preprocessing_train(df_features_train)\n",
    "decor_dataset_test = preprocessing_test(df_features_test, mean_std, selector, to_drop)\n",
    "print(\"features processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c55dc7-e97b-42b9-9cab-0786f85a747c",
   "metadata": {},
   "source": [
    "### STEP 3: Select optimal features \n",
    "#### WRAPPER FEATURE SELECTION: Recursive Feature Elimination with cross-validation\n",
    "The model currently used is XGBClassifier, it is possible to change it to compare different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5603e0-7b37-4e6f-a529-b163d711866f",
   "metadata": {},
   "source": [
    "#### RECURSIVE FEATURE ELIMINATION (NO CROSS VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929804cf-0531-4bd3-9b87-ff96e3db2a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model: XGBoost Classifier\n",
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier(\n",
    "    gamma=0.5,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=3,\n",
    "    min_child_weight=5,\n",
    "    n_estimators=890,\n",
    "    use_label_encoder=False,\n",
    "    colsample_bytree=1,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    seed=27,\n",
    "    random_state=27\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09a397-e8aa-4b29-8496-70d2e7a505dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rfe = RFE(estimator=model, n_features_to_select=11, step=1)\n",
    "rfe.fit(decor_dataset_train, outcome_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f843bd-fc21-4867-9bc3-d9dd16532715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: Extract selected features immediately after fit\n",
    "\n",
    "support = rfe.support_\n",
    "selected_features = decor_dataset_train.columns[support].tolist()\n",
    "\n",
    "print(f\"Selected exactly {len(selected_features)} features (as requested):\")\n",
    "print(selected_features)\n",
    "\n",
    "# Create reduced datasets with ONLY these 11 features\n",
    "reduced_features_train = decor_dataset_train[selected_features].copy()\n",
    "reduced_features_test  = decor_dataset_test[selected_features].copy()\n",
    "\n",
    "print(\"\\nReduced train shape:\", reduced_features_train.shape)   # Should be (1811, 11)\n",
    "print(\"Reduced test shape: \", reduced_features_test.shape)     # Should be (454, 11)\n",
    "print(\"Model expects:\", rfe.estimator_.n_features_in_, \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805c0f0-883a-479c-a05b-7be4436b4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model: Support vector Machine\n",
    "svm = sklearn.svm.SVC(kernel=\"linear\", probability=True,\n",
    "                     class_weight=\"balanced\", random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f0044f-d696-470a-8cd0-17387d3dd19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_svm = RFE(estimator=svm, n_features_to_select=11)\n",
    "rfe_svm.fit(decor_dataset_train, outcome_train)\n",
    "support_svm = rfe_svm.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa857b9-ed07-4dbf-950b-a8e2cd353f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model: Random forest\n",
    "rf = sklearn.ensemble.RandomForestClassifier(min_samples_leaf=8, random_state=27,\n",
    "                                            class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812378d-23b3-469d-a230-132228e60475",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_rf = RFE(estimator=rf, n_features_to_select=11)\n",
    "rfe_rf.fit(decor_dataset_train, outcome_train)\n",
    "support_rf = rfe_rf.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada40d06-e612-4087-b782-59d5828bcc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model: LogisticRegression\n",
    "logreg = sklearn.linear_model.LogisticRegression(solver=\"liblinear\", max_iter=5000,\n",
    "                                                 class_weight=\"balanced\", random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ea5d2-15ac-4bb5-a911-0d4e1209ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_logreg = RFE(estimator=logreg, n_features_to_select=11)\n",
    "rfe_logreg.fit(decor_dataset_train, outcome_train)\n",
    "support_logreg = rfe_logreg.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d810f8-84a9-4ebe-becd-56eec4194141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ── Define output directory once ──\n",
    "save_dir = os.path.expanduser(\"~/Documents/Features\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "print(f\"Results will be saved to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6242ca3-256f-4d0c-84a3-e1a5515ad684",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### RECURSIVE FEATURE ELIMINATION WITH CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776efe7d-80f9-42bf-88cb-73dd45a0d582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(10),\n",
    "              scoring='roc_auc',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "rfecv.fit(decor_dataset_train, outcome_train)\n",
    "support = rfecv.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0802bcd-8886-4c6d-b12b-0b2cca0f4c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv.cv_results_[\"mean_test_score\"]\n",
    "rfecv.cv_results_[\"std_test_score\"]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(\n",
    "    range(\n",
    "        min_features_to_select,\n",
    "        min_features_to_select + len(rfecv.cv_results_[\"mean_test_score\"])\n",
    "    ),\n",
    "    rfecv.cv_results_[\"mean_test_score\"]\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Number of selected features\")\n",
    "plt.ylabel(\"Mean CV ROC-AUC\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26863d4a-9315-4965-b945-6a79fcf2231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of features selected\n",
    "support.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07dc3e-75fa-4fd7-a9b4-a7c0aadbaddd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### FILTER FEATURE SELECTION: ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae09d6-f7f5-42e0-a4eb-4f8d8bc310f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Build pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"anova\", SelectKBest(score_func=f_classif)),\n",
    "    (\"model\", model),\n",
    "])\n",
    "\n",
    "# Grid of k values\n",
    "param_grid = {\n",
    "    \"anova__k\": [5, 10, 15, 20, 30, 40, 45, 50, 60, 70, 80, 90, 100, \"all\"]\n",
    "}\n",
    "\n",
    "# CV strategy\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Grid search\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "gsearch.fit(decor_dataset_train, outcome_train)\n",
    "\n",
    "# Results\n",
    "print(\"Best k:\", gsearch.best_params_[\"anova__k\"])\n",
    "print(\"Best CV AUC:\", gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff6880-c060-4e37-ba98-ce53e9d7fc69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### EMBEDDED FEATURE SELECTION: LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675db1e7-d0ef-4baf-bef9-021c810bce17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "logit_l1 = LogisticRegressionCV(\n",
    "    penalty=\"l1\",\n",
    "    solver=\"saga\",         \n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10,\n",
    "    max_iter=10000,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on your training data\n",
    "logit_l1.fit(decor_dataset_train, outcome_train)\n",
    "\n",
    "# Selected features\n",
    "coef = logit_l1.coef_.ravel()\n",
    "n_features_selected = (coef != 0).sum()\n",
    "\n",
    "print(\"Best C:\", logit_l1.C_[0])\n",
    "print(f\"Features selected: {n_features_selected} out of {decor_dataset_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a17995-6baa-4e43-97be-380a30687bc2",
   "metadata": {},
   "source": [
    "#### MODEL TRAINING : XGBOOST + EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d10fb-d978-4347-972a-951d9ba7f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the selected features only\n",
    "filtered_col = np.extract(support, np.array(decor_dataset_test.columns))\n",
    "reduced_features_test = decor_dataset_test[filtered_col]\n",
    "reduced_features_train = decor_dataset_train[filtered_col]\n",
    "print(\"features processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c5a85-f9df-44cf-b060-8d57df31a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images_test = list(df_features_test.index)\n",
    "\n",
    "#predict case by case for test\n",
    "\n",
    "all_predictions = []\n",
    "for i,index in enumerate(path_images_test):\n",
    "        temp_proba = rfe.estimator_.predict_proba(reduced_features_test.iloc[i].values.reshape(1, -1)) #look into what estimator_ does\n",
    "        all_predictions.append(temp_proba)\n",
    "\n",
    "all_predictions_test = np.array([prediction[0][1] for prediction in all_predictions])\n",
    "\n",
    "file = open(os.path.expanduser(\"~/Documents/Features\") + \"/\" + ntpath.basename(\"/probabilities_test\").split(\".\")[0]+\".pkl\", \"wb\")\n",
    "pickle.dump(all_predictions_test, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efc490-7287-4808-bc17-e14605825a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DETERMINING THE OPTIMAL THRESHHOLD FOR CLASSIFICATION BOUNDARY\n",
    "## This is not for evaluation since it is on the training dataset.\n",
    "\n",
    "path_images_train = list(df_features_train.index)\n",
    "\n",
    "#predict case by case for train to obtain optimal threshhold\n",
    "\n",
    "all_predictions = []\n",
    "for i,index in enumerate(path_images_train):\n",
    "        temp_proba = rfe.estimator_.predict_proba(reduced_features_train.iloc[i].values.reshape(1, -1)) #look into what estimator_ does\n",
    "        all_predictions.append(temp_proba)\n",
    "\n",
    "all_predictions_train = np.array([prediction[0][1] for prediction in all_predictions])\n",
    "\n",
    "file = open(os.path.expanduser(\"~/Documents/Features\") + \"/\" + ntpath.basename(\"/probabilities_train\").split(\".\")[0]+\".pkl\", \"wb\")\n",
    "pickle.dump(all_predictions_train, file)\n",
    "file.close()\n",
    "\n",
    "#Determine optimal threshhold\n",
    "\n",
    "optimal_threshold = get_optimal_threshold(outcome_train, all_predictions_train) # (true_outcome, predictions): to obtain a good threshold based on the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf5f56-76b1-490c-959e-979f46b6d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94f233-9258-4d5f-ad2d-45025cd6c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_test_array = np.array(outcome_test)\n",
    "df_distributions, df_results = get_stats_with_ci(outcome_test_array, all_predictions_test, 'test_set_results', optimal_threshold) #(y_label, y_pred, label, optimal_threshold, nsamples=2000):\n",
    "##optimal threshold: reuse the one computed on the train dataset\n",
    "##label: index of the dataframe, can be \"external radiomics results\"\n",
    "##returns a dataframe with auc accuracy precision recall f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bdb333-b8f8-4a9b-88a0-b78403f1b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb884e47-6363-4a78-a80d-501d8d094506",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_binary = (np.array(all_predictions_test) > optimal_threshold).astype(int)\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_true=outcome_test_array, y_pred=predictions_test_binary, normalize='true')\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rfe.classes_)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb317f-3397-4a0d-8696-ecd0a6997e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RFE Classifier\"\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(outcome_test, all_predictions_test)\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "ax.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.3f})', color='purple',)\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier (AUC = 0.500)')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curve', fontsize=14)\n",
    "ax.legend(loc=\"lower right\", fontsize=15)\n",
    "ax.grid(alpha=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5e11b-7f94-489b-b498-66a484462343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#auc_values, text_auc_summary, upper_lower_ci, mean_tpr = get_ci_for_auc(outcome_test_array, all_predictions_test)\n",
    "\n",
    "#perhaps this could be used to create CI around the ROC curve? No luck so far though, seems like I'd have to set up a new function for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5889761-36eb-49c0-9603-f952014e5ca6",
   "metadata": {},
   "source": [
    "#### MODEL TRAINING: SVM + EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b001a38a-8129-43c7-9e0f-1701cea7c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create reduced datasets\n",
    "reduced_features_train_svm = decor_dataset_train[selected_features_svm].copy()\n",
    "reduced_features_test_svm = decor_dataset_test[selected_features_svm].copy()\n",
    "print(\"Reduced train shape (SVM):\", reduced_features_train_svm.shape)\n",
    "print(\"Reduced test shape (SVM):\", reduced_features_test_svm.shape)\n",
    "\n",
    "# Predict probabilities on test set\n",
    "all_predictions_test_svm = rfe_svm.estimator_.predict_proba(reduced_features_test_svm)[:, 1]\n",
    "\n",
    "# Save test probs (optional)\n",
    "test_path_svm = os.path.join(save_dir, \"probabilities_test_svm.pkl\")\n",
    "with open(test_path_svm, \"wb\") as f:\n",
    "    pickle.dump(all_predictions_test_svm, f)\n",
    "print(f\"Saved SVM test probabilities: {test_path_svm}\")\n",
    "\n",
    "# Predict probabilities on train set (for threshold)\n",
    "all_predictions_train_svm = rfe_svm.estimator_.predict_proba(reduced_features_train_svm)[:, 1]\n",
    "train_path_svm = os.path.join(save_dir, \"probabilities_train_svm.pkl\")\n",
    "with open(train_path_svm, \"wb\") as f:\n",
    "    pickle.dump(all_predictions_train_svm, f)\n",
    "print(f\"Saved SVM train probabilities: {train_path_svm}\")\n",
    "\n",
    "# Optimal threshold\n",
    "optimal_threshold_svm = get_optimal_threshold(outcome_train, all_predictions_train_svm)\n",
    "print(\"Optimal threshold (SVM):\", optimal_threshold_svm)\n",
    "\n",
    "# Metrics with CI\n",
    "df_distributions_svm, df_results_svm = get_stats_with_ci(outcome_test_array, all_predictions_test_svm, 'test_set_results_svm', optimal_threshold_svm)\n",
    "display(df_results_svm)\n",
    "\n",
    "# Confusion Matrix\n",
    "predictions_test_binary_svm = (all_predictions_test_svm > optimal_threshold_svm).astype(int)\n",
    "cm_svm = confusion_matrix(outcome_test_array, predictions_test_binary_svm, normalize='true')\n",
    "disp_svm = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm_svm, display_labels=rfe_svm.classes_)\n",
    "disp_svm.plot()\n",
    "plt.title(\"Confusion Matrix (SVM)\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr_svm, tpr_svm, _ = sklearn.metrics.roc_curve(outcome_test, all_predictions_test_svm)\n",
    "roc_auc_svm = sklearn.metrics.auc(fpr_svm, tpr_svm)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.plot(fpr_svm, tpr_svm, lw=2, label=f'SVM (AUC = {roc_auc_svm:.3f})', color='green')\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.500)')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve (SVM)')\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(alpha=1)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a1e963-7cd2-4192-86be-115b0de6c8ad",
   "metadata": {},
   "source": [
    "#### MODEL TRAINING: RANDOM FOREST: EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5efb8-85bd-4bc6-a912-8f80c8075dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract selected features for RF\n",
    "selected_features_rf = decor_dataset_train.columns[support_rf].tolist()\n",
    "print(f\"Selected {len(selected_features_rf)} features for RF: {selected_features_rf}\")\n",
    "\n",
    "# Create reduced datasets\n",
    "reduced_features_train_rf = decor_dataset_train[selected_features_rf].copy()\n",
    "reduced_features_test_rf = decor_dataset_test[selected_features_rf].copy()\n",
    "print(\"Reduced train shape (RF):\", reduced_features_train_rf.shape)\n",
    "print(\"Reduced test shape (RF):\", reduced_features_test_rf.shape)\n",
    "\n",
    "# Predict probabilities on test set\n",
    "all_predictions_test_rf = rfe_rf.estimator_.predict_proba(reduced_features_test_rf)[:, 1]\n",
    "\n",
    "# Save test probs (optional)\n",
    "test_path_rf = os.path.join(save_dir, \"probabilities_test_rf.pkl\")\n",
    "with open(test_path_rf, \"wb\") as f:\n",
    "    pickle.dump(all_predictions_test_rf, f)\n",
    "print(f\"Saved RF test probabilities: {test_path_rf}\")\n",
    "\n",
    "# Predict probabilities on train set (for threshold)\n",
    "all_predictions_train_rf = rfe_rf.estimator_.predict_proba(reduced_features_train_rf)[:, 1]\n",
    "train_path_rf = os.path.join(save_dir, \"probabilities_train_rf.pkl\")\n",
    "with open(train_path_rf, \"wb\") as f:\n",
    "    pickle.dump(all_predictions_train_rf, f)\n",
    "print(f\"Saved RF train probabilities: {train_path_rf}\")\n",
    "\n",
    "# Optimal threshold\n",
    "optimal_threshold_rf = get_optimal_threshold(outcome_train, all_predictions_train_rf)\n",
    "print(\"Optimal threshold (RF):\", optimal_threshold_rf)\n",
    "\n",
    "# Metrics with CI\n",
    "df_distributions_rf, df_results_rf = get_stats_with_ci(outcome_test_array, all_predictions_test_rf, 'test_set_results_rf', optimal_threshold_rf)\n",
    "display(df_results_rf)\n",
    "\n",
    "# Confusion Matrix\n",
    "predictions_test_binary_rf = (all_predictions_test_rf > optimal_threshold_rf).astype(int)\n",
    "cm_rf = confusion_matrix(outcome_test_array, predictions_test_binary_rf, normalize='true')\n",
    "disp_rf = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=rfe_rf.classes_)\n",
    "disp_rf.plot()\n",
    "plt.title(\"Confusion Matrix (RF)\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr_rf, tpr_rf, _ = sklearn.metrics.roc_curve(outcome_test, all_predictions_test_rf)\n",
    "roc_auc_rf = sklearn.metrics.auc(fpr_rf, tpr_rf)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.plot(fpr_rf, tpr_rf, lw=2, label=f'RF (AUC = {roc_auc_rf:.3f})', color='red')\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.500)')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve (RF)')\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(alpha=1)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6498cc-0ca2-40aa-9583-d3643950ac2d",
   "metadata": {},
   "source": [
    "#### MODEL TRAINING: LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0e63d-e926-463d-be0a-7ad157021391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract selected features for LogReg\n",
    "selected_features_logreg = decor_dataset_train.columns[support_logreg].tolist()\n",
    "print(f\"Selected {len(selected_features_logreg)} features for LogReg: {selected_features_logreg}\")\n",
    "\n",
    "# Create reduced datasets\n",
    "reduced_features_train_logreg = decor_dataset_train[selected_features_logreg].copy()\n",
    "reduced_features_test_logreg = decor_dataset_test[selected_features_logreg].copy()\n",
    "print(\"Reduced train shape (LogReg):\", reduced_features_train_logreg.shape)\n",
    "print(\"Reduced test shape (LogReg):\", reduced_features_test_logreg.shape)\n",
    "\n",
    "# Predict probabilities on test set\n",
    "all_predictions_test_logreg = rfe_logreg.estimator_.predict_proba(reduced_features_test_logreg)[:, 1]\n",
    "\n",
    "# Save test probs (optional, like your XGBoost)\n",
    "save_dir = os.path.expanduser(\"~/Documents/Features\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "test_path_logreg = os.path.join(save_dir, \"probabilities_test_logreg.pkl\")\n",
    "with open(test_path_logreg, \"wb\") as f:\n",
    "    pickle.dump(all_predictions_test_logreg, f)\n",
    "print(f\"Saved LogReg test probabilities: {test_path_logreg}\")\n",
    "\n",
    "# Predict probabilities on train set (for threshold)\n",
    "all_predictions_train_logreg = rfe_logreg.estimator_.predict_proba(reduced_features_train_logreg)[:, 1]\n",
    "train_path_logreg = os.path.join(save_dir, \"probabilities_train_logreg.pkl\")\n",
    "with open(train_path_logreg, \"wb\") as f:\n",
    "    pickle.dump(all_predictions_train_logreg, f)\n",
    "print(f\"Saved LogReg train probabilities: {train_path_logreg}\")\n",
    "\n",
    "# Optimal threshold\n",
    "optimal_threshold_logreg = get_optimal_threshold(outcome_train, all_predictions_train_logreg)\n",
    "print(\"Optimal threshold (LogReg):\", optimal_threshold_logreg)\n",
    "\n",
    "# Metrics with CI\n",
    "outcome_test_array = np.array(outcome_test)\n",
    "df_distributions_logreg, df_results_logreg = get_stats_with_ci(outcome_test_array, all_predictions_test_logreg, 'test_set_results_logreg', optimal_threshold_logreg)\n",
    "display(df_results_logreg)\n",
    "\n",
    "# Confusion Matrix\n",
    "predictions_test_binary_logreg = (all_predictions_test_logreg > optimal_threshold_logreg).astype(int)\n",
    "cm_logreg = confusion_matrix(outcome_test_array, predictions_test_binary_logreg, normalize='true')\n",
    "disp_logreg = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm_logreg, display_labels=rfe_logreg.classes_)\n",
    "disp_logreg.plot()\n",
    "plt.title(\"Confusion Matrix (LogReg)\")\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr_logreg, tpr_logreg, _ = sklearn.metrics.roc_curve(outcome_test, all_predictions_test_logreg)\n",
    "roc_auc_logreg = sklearn.metrics.auc(fpr_logreg, tpr_logreg)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.plot(fpr_logreg, tpr_logreg, lw=2, label=f'LogReg (AUC = {roc_auc_logreg:.3f})', color='blue')\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.500)')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curve (LogReg)')\n",
    "ax.legend(loc=\"lower right\")\n",
    "ax.grid(alpha=1)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc7e4f0-383b-474a-a705-0de5a6490210",
   "metadata": {},
   "source": [
    "## SHAP VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d2d85a-d13e-4412-8b46-865417f0d9bd",
   "metadata": {},
   "source": [
    "##### XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f059d-4bd9-44f1-a929-447ea958e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "X100 = shap.utils.sample(reduced_features_train, 100) # I am not yet sure what the optimal number for distribution is. Standard (explained in documentation is 100.\n",
    "explainer_xgb = shap.Explainer(rfe.estimator_, X100) #This utilises the rfe xgboost with 10 features\n",
    "shap_values_xgb = explainer_xgb(reduced_features_train) #based on training dataset of model, since that is what controls final model architecture\n",
    "shap.plots.beeswarm(shap_values_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbf32b-afe4-41d4-bd04-c00ddf24f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_case = random.randint(0, len(reduced_features_train + 1))\n",
    "print(\"case index: \" + str(random_case))\n",
    "\n",
    "shap.plots.waterfall(shap_values_xgb[random_case])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
