{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce52ea82-9e2f-4b01-b86c-cadb5538ff03",
   "metadata": {},
   "source": [
    "# PIPELINE DATA LOADING AND PREPROCESSING\n",
    "This notebook documents the data loading, preprocessing of radiomics features, and feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32766547-ad4a-4037-bbf9-1d57fa51fe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in /opt/anaconda3/lib/python3.13/site-packages (0.50.0)\n",
      "Requirement already satisfied: numpy>=2 in /opt/anaconda3/lib/python3.13/site-packages (from shap) (2.3.5)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from shap) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (from shap) (1.7.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (from shap) (2.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /opt/anaconda3/lib/python3.13/site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in /opt/anaconda3/lib/python3.13/site-packages (from shap) (25.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in /opt/anaconda3/lib/python3.13/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in /opt/anaconda3/lib/python3.13/site-packages (from shap) (0.62.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.13/site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.13/site-packages (from shap) (4.15.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /opt/anaconda3/lib/python3.13/site-packages (from numba>=0.54->shap) (0.45.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->shap) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.13/site-packages (3.1.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from xgboost) (2.3.5)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (from xgboost) (1.16.3)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'radiomics_pipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, StratifiedKFold\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Now import from radiomics_pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mradiomics_pipeline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocessing_train, preprocessing_test, get_results, get_ci, get_stats_with_ci, get_ci_for_auc, get_optimal_threshold\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'radiomics_pipeline'"
     ]
    }
   ],
   "source": [
    "!pip install shap\n",
    "!pip install xgboost\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import ntpath\n",
    "import sklearn\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "\n",
    "# Now import from radiomics_pipeline\n",
    "from radiomics_pipeline.utils import preprocessing_train, preprocessing_test, get_results, get_ci, get_stats_with_ci, get_ci_for_auc, get_optimal_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fa9e6-1b3c-48ef-9d86-53a03d0381a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### STEP 1: Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a426861c-e576-4d76-a6fd-2942cdb23440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load features\n",
    "df_features_train = pd.read_csv(\"//Users/noura/Desktop/idk/train_merged_LE_RE.csv\")\n",
    "outcome_train = list(df_features_train[\"outcome\"])\n",
    "df_features_train.drop([\"mask_name\",\"outcome\"], inplace=True, axis=1)\n",
    "df_features_test = pd.read_csv(\"/Users/noura/Desktop/idk/test_merged_LE_RE.csv\")\n",
    "outcome_test = list(df_features_test[\"outcome\"])\n",
    "df_features_test.drop([\"mask_name\",\"outcome\"], inplace=True, axis=1)\n",
    "\n",
    "#The below gives the error 'Outcome' (not a column in df features test), this has to be fixed in the merge file itself.\n",
    "\n",
    "#df_features_external = pd.read_csv(\"~/Documents/Features/external_merged_LE_RE.csv\")\n",
    "#outcome_external = list(df_features_test[\"outcome\"])\n",
    "#df_features_external.drop([\"mask_name\",\"outcome\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e6bccf-0afb-4d15-81c5-b188c390a4ce",
   "metadata": {},
   "source": [
    "### STEP 2: Preprocessing features\n",
    "The preprocessing of the features is present in radiomics_pipeline.utils.\n",
    "\n",
    "It includes:\n",
    "- Normalization\n",
    "- Low variance feature removal (variance below 0.01)\n",
    "- Highly correlated feature removal (Spearman correlation matrix, correlation > 0.85, dropping one feature based on heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00bd59b3-a550-449d-af04-dd4f9183b9e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mean_std, selector, to_drop, decor_dataset_train = \u001b[43mpreprocessing_train\u001b[49m(df_features_train)\n\u001b[32m      2\u001b[39m decor_dataset_test = preprocessing_test(df_features_test, mean_std, selector, to_drop)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mfeatures processed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'preprocessing_train' is not defined"
     ]
    }
   ],
   "source": [
    "mean_std, selector, to_drop, decor_dataset_train = preprocessing_train(df_features_train)\n",
    "decor_dataset_test = preprocessing_test(df_features_test, mean_std, selector, to_drop)\n",
    "print(\"features processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c55dc7-e97b-42b9-9cab-0786f85a747c",
   "metadata": {},
   "source": [
    "### STEP 3: Select optimal features \n",
    "#### WRAPPER FEATURE SELECTION: Recursive Feature Elimination with cross-validation\n",
    "The model currently used is XGBClassifier, it is possible to change it to compare different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5603e0-7b37-4e6f-a529-b163d711866f",
   "metadata": {},
   "source": [
    "#### RECURSIVE FEATURE ELIMINATION (NO CROSS VALIDATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929804cf-0531-4bd3-9b87-ff96e3db2a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model: XGBoost Classifier\n",
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier(use_label_encoder=False, colsample_bytree=1,\n",
    "                          objective='binary:logistic', eval_metric='logloss', nthread=4, scale_pos_weight=1,\n",
    "                          seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a09a397-e8aa-4b29-8496-70d2e7a505dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decor_dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m rfe = RFE(estimator=model, n_features_to_select=\u001b[32m10\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m rfe.fit(\u001b[43mdecor_dataset_train\u001b[49m, outcome_train)\n\u001b[32m      3\u001b[39m support = rfe.support_\n",
      "\u001b[31mNameError\u001b[39m: name 'decor_dataset_train' is not defined"
     ]
    }
   ],
   "source": [
    "rfe = RFE(estimator=model, n_features_to_select=10)\n",
    "rfe.fit(decor_dataset_train, outcome_train)\n",
    "support = rfe.support_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6242ca3-256f-4d0c-84a3-e1a5515ad684",
   "metadata": {},
   "source": [
    "#### RECURSIVE FEATURE ELIMINATION WITH CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "776efe7d-80f9-42bf-88cb-73dd45a0d582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decor_dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m min_features_to_select = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# Minimum number of features to consider\u001b[39;00m\n\u001b[32m      2\u001b[39m rfecv = RFECV(estimator=model, step=\u001b[32m1\u001b[39m, cv=StratifiedKFold(\u001b[32m10\u001b[39m),\n\u001b[32m      3\u001b[39m               scoring=\u001b[33m'\u001b[39m\u001b[33mroc_auc\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m               min_features_to_select=min_features_to_select)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m rfecv.fit(\u001b[43mdecor_dataset_train\u001b[49m, outcome_train)\n\u001b[32m      6\u001b[39m support = rfecv.support_\n",
      "\u001b[31mNameError\u001b[39m: name 'decor_dataset_train' is not defined"
     ]
    }
   ],
   "source": [
    "min_features_to_select = 1  # Minimum number of features to consider\n",
    "rfecv = RFECV(estimator=model, step=1, cv=StratifiedKFold(10),\n",
    "              scoring='roc_auc',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "rfecv.fit(decor_dataset_train, outcome_train)\n",
    "support = rfecv.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0802bcd-8886-4c6d-b12b-0b2cca0f4c93",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RFECV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrfecv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcv_results_\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mmean_test_score\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      2\u001b[39m rfecv.cv_results_[\u001b[33m\"\u001b[39m\u001b[33mstd_test_score\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'RFECV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "rfecv.cv_results_[\"mean_test_score\"]\n",
    "rfecv.cv_results_[\"std_test_score\"]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(\n",
    "    range(\n",
    "        min_features_to_select,\n",
    "        min_features_to_select + len(rfecv.cv_results_[\"mean_test_score\"])\n",
    "    ),\n",
    "    rfecv.cv_results_[\"mean_test_score\"]\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Number of selected features\")\n",
    "plt.ylabel(\"Mean CV ROC-AUC\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26863d4a-9315-4965-b945-6a79fcf2231f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'support' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#number of features selected\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msupport\u001b[49m.sum()\n",
      "\u001b[31mNameError\u001b[39m: name 'support' is not defined"
     ]
    }
   ],
   "source": [
    "#number of features selected\n",
    "support.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07dc3e-75fa-4fd7-a9b4-a7c0aadbaddd",
   "metadata": {},
   "source": [
    "#### FILTER FEATURE SELECTION: ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ae09d6-f7f5-42e0-a4eb-4f8d8bc310f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decor_dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     20\u001b[39m gsearch = GridSearchCV(\n\u001b[32m     21\u001b[39m     estimator=pipe,\n\u001b[32m     22\u001b[39m     param_grid=param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     26\u001b[39m )\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Fit\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m gsearch.fit(\u001b[43mdecor_dataset_train\u001b[49m, outcome_train)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Results\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest k:\u001b[39m\u001b[33m\"\u001b[39m, gsearch.best_params_[\u001b[33m\"\u001b[39m\u001b[33manova__k\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'decor_dataset_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# Build pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"anova\", SelectKBest(score_func=f_classif)),\n",
    "    (\"model\", model),\n",
    "])\n",
    "\n",
    "# Grid of k values\n",
    "param_grid = {\n",
    "    \"anova__k\": [5, 10, 15, 20, 30, 40, 45, 50, 60, 70, 80, 90, 100, \"all\"]\n",
    "}\n",
    "\n",
    "# CV strategy\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Grid search\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit\n",
    "gsearch.fit(decor_dataset_train, outcome_train)\n",
    "\n",
    "# Results\n",
    "print(\"Best k:\", gsearch.best_params_[\"anova__k\"])\n",
    "print(\"Best CV AUC:\", gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff6880-c060-4e37-ba98-ce53e9d7fc69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### EMBEDDED FEATURE SELECTION: LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675db1e7-d0ef-4baf-bef9-021c810bce17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "logit_l1 = LogisticRegressionCV(\n",
    "    penalty=\"l1\",\n",
    "    solver=\"saga\",         \n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10,\n",
    "    max_iter=10000,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on your training data\n",
    "logit_l1.fit(decor_dataset_train, outcome_train)\n",
    "\n",
    "# Selected features\n",
    "coef = logit_l1.coef_.ravel()\n",
    "n_features_selected = (coef != 0).sum()\n",
    "\n",
    "print(\"Best C:\", logit_l1.C_[0])\n",
    "print(f\"Features selected: {n_features_selected} out of {decor_dataset_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a17995-6baa-4e43-97be-380a30687bc2",
   "metadata": {},
   "source": [
    "#### MODEL TRAINING : XGBOOST + EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b99d10fb-d978-4347-972a-951d9ba7f0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features processed\n"
     ]
    }
   ],
   "source": [
    "#use the selected features only\n",
    "filtered_col = np.extract(support, np.array(decor_dataset_test.columns))\n",
    "reduced_features_test = decor_dataset_test[filtered_col]\n",
    "reduced_features_train = decor_dataset_train[filtered_col]\n",
    "print(\"features processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "924c5a85-f9df-44cf-b060-8d57df31a68b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 10, got 45",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m all_predictions = []\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i,index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(path_images_test):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         temp_proba = \u001b[43mrfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduced_features_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#look into what estimator_ does\u001b[39;00m\n\u001b[32m      8\u001b[39m         all_predictions.append(temp_proba)\n\u001b[32m     10\u001b[39m all_predictions_test = np.array([prediction[\u001b[32m0\u001b[39m][\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m prediction \u001b[38;5;129;01min\u001b[39;00m all_predictions])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/xgboost/sklearn.py:1923\u001b[39m, in \u001b[36mXGBClassifier.predict_proba\u001b[39m\u001b[34m(self, X, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1921\u001b[39m     class_prob = softmax(raw_predt, axis=\u001b[32m1\u001b[39m)\n\u001b[32m   1922\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m class_prob\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m class_probs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1927\u001b[39m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1928\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1929\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _cls_predict_proba(\u001b[38;5;28mself\u001b[39m.n_classes_, class_probs, np.vstack)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/xgboost/core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/xgboost/sklearn.py:1448\u001b[39m, in \u001b[36mXGBModel.predict\u001b[39m\u001b[34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._can_use_inplace_predict():\n\u001b[32m   1447\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1448\u001b[39m         predts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1450\u001b[39m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1451\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmargin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1452\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1453\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1454\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1455\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1456\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[32m   1457\u001b[39m             cp = import_cupy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/xgboost/core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/xgboost/core.py:2865\u001b[39m, in \u001b[36mBooster.inplace_predict\u001b[39m\u001b[34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[39m\n\u001b[32m   2860\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   2861\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`shape` attribute is required when `validate_features` is True\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2862\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2863\u001b[39m         )\n\u001b[32m   2864\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data.shape) != \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_features() != data.shape[\u001b[32m1\u001b[39m]:\n\u001b[32m-> \u001b[39m\u001b[32m2865\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2866\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.num_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2867\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2868\u001b[39m         )\n\u001b[32m   2870\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_np_array_like(data):\n\u001b[32m   2871\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _ensure_np_dtype\n",
      "\u001b[31mValueError\u001b[39m: Feature shape mismatch, expected: 10, got 45"
     ]
    }
   ],
   "source": [
    "path_images_test = list(df_features_test.index)\n",
    "\n",
    "#predict case by case for test\n",
    "\n",
    "all_predictions = []\n",
    "for i,index in enumerate(path_images_test):\n",
    "        temp_proba = rfe.estimator_.predict_proba(reduced_features_test.iloc[i].values.reshape(1, -1)) #look into what estimator_ does\n",
    "        all_predictions.append(temp_proba)\n",
    "\n",
    "all_predictions_test = np.array([prediction[0][1] for prediction in all_predictions])\n",
    "\n",
    "file = open(os.path.expanduser(\"~/Documents/Features\") + \"/\" + ntpath.basename(\"/probabilities_test\").split(\".\")[0]+\".pkl\", \"wb\")\n",
    "pickle.dump(all_predictions_test, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efc490-7287-4808-bc17-e14605825a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DETERMINING THE OPTIMAL THRESHHOLD FOR CLASSIFICATION BOUNDARY\n",
    "## This is not for evaluation since it is on the training dataset.\n",
    "\n",
    "path_images_train = list(df_features_train.index)\n",
    "\n",
    "#predict case by case for train to obtain optimal threshhold\n",
    "\n",
    "all_predictions = []\n",
    "for i,index in enumerate(path_images_train):\n",
    "        temp_proba = rfe.estimator_.predict_proba(reduced_features_train.iloc[i].values.reshape(1, -1)) #look into what estimator_ does\n",
    "        all_predictions.append(temp_proba)\n",
    "\n",
    "all_predictions_train = np.array([prediction[0][1] for prediction in all_predictions])\n",
    "\n",
    "file = open(os.path.expanduser(\"~/Documents/Features\") + \"/\" + ntpath.basename(\"/probabilities_train\").split(\".\")[0]+\".pkl\", \"wb\")\n",
    "pickle.dump(all_predictions_train, file)\n",
    "file.close()\n",
    "\n",
    "#Determine optimal threshhold\n",
    "\n",
    "optimal_threshold = get_optimal_threshold(outcome_train, all_predictions_train) # (true_outcome, predictions): to obtain a good threshold based on the train dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf5f56-76b1-490c-959e-979f46b6d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94f233-9258-4d5f-ad2d-45025cd6c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_test_array = np.array(outcome_test)\n",
    "df_distributions, df_results = get_stats_with_ci(outcome_test_array, all_predictions_test, 'test_set_results', optimal_threshold) #(y_label, y_pred, label, optimal_threshold, nsamples=2000):\n",
    "##optimal threshold: reuse the one computed on the train dataset\n",
    "##label: index of the dataframe, can be \"external radiomics results\"\n",
    "##returns a dataframe with auc accuracy precision recall f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bdb333-b8f8-4a9b-88a0-b78403f1b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb884e47-6363-4a78-a80d-501d8d094506",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test_binary = (np.array(all_predictions_test) > optimal_threshold).astype(int)\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(y_true=outcome_test_array, y_pred=predictions_test_binary, normalize='true')\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rfe.classes_)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb317f-3397-4a0d-8696-ecd0a6997e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RFE Classifier\"\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(outcome_test, all_predictions_test)\n",
    "roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "\n",
    "ax.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.3f})', color='purple',)\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier (AUC = 0.500)')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12)\n",
    "ax.set_title('ROC Curve', fontsize=14)\n",
    "ax.legend(loc=\"lower right\", fontsize=15)\n",
    "ax.grid(alpha=1)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5e11b-7f94-489b-b498-66a484462343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#auc_values, text_auc_summary, upper_lower_ci, mean_tpr = get_ci_for_auc(outcome_test_array, all_predictions_test)\n",
    "\n",
    "#perhaps this could be used to create CI around the ROC curve? No luck so far though, seems like I'd have to set up a new function for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc7e4f0-383b-474a-a705-0de5a6490210",
   "metadata": {},
   "source": [
    "#### SHAP VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f19f059d-4bd9-44f1-a929-447ea958e878",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduced_features_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X100 = shap.utils.sample(\u001b[43mreduced_features_train\u001b[49m, \u001b[32m100\u001b[39m) \u001b[38;5;66;03m# I am not yet sure what the optimal number for distribution is. Standard (explained in documentation is 100.\u001b[39;00m\n\u001b[32m      2\u001b[39m explainer_xgb = shap.Explainer(rfe.estimator_, X100) \u001b[38;5;66;03m#This utilises the rfe xgboost with 10 features\u001b[39;00m\n\u001b[32m      3\u001b[39m shap_values_xgb = explainer_xgb(reduced_features_train) \u001b[38;5;66;03m#based on training dataset of model, since that is what controls final model architecture\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'reduced_features_train' is not defined"
     ]
    }
   ],
   "source": [
    "X100 = shap.utils.sample(reduced_features_train, 100) # I am not yet sure what the optimal number for distribution is. Standard (explained in documentation is 100.\n",
    "explainer_xgb = shap.Explainer(rfe.estimator_, X100) #This utilises the rfe xgboost with 10 features\n",
    "shap_values_xgb = explainer_xgb(reduced_features_train) #based on training dataset of model, since that is what controls final model architecture\n",
    "shap.plots.beeswarm(shap_values_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbf32b-afe4-41d4-bd04-c00ddf24f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_case = random.randint(0, len(reduced_features_train + 1))\n",
    "print(\"case index: \" + str(random_case))\n",
    "\n",
    "shap.plots.waterfall(shap_values_xgb[random_case])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
